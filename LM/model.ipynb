{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2729584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams\n",
    "from nltk import ConditionalFreqDist as CFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9b1e6",
   "metadata": {},
   "source": [
    "#### Part 1:  Building an N-Gram Language Model Using the NLTK Brown Corpus\n",
    "\n",
    "In this section, a statistical LM is created using the **Brown Corpus** from NLTK library. \n",
    "The data is preprocessed into all lower case words and adds the BOS and EOS for every sentence.\n",
    "\n",
    "The LM is built using a **Bigram Model:**\n",
    "\n",
    "$$\n",
    "P(w_i \\mid w_{i-1})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca12aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for sentences in brown.sents():\n",
    "    tokens.append(\"<s>\") # Add BOS and EOS for each sentence\n",
    "\n",
    "    for words in sentences:\n",
    "        tokens.append(words.lower()) # Reduce vocabulary size The != the\n",
    "    tokens.append(\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e478bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = list(bigrams(tokens))\n",
    "bigram_table = CFD(bigram)\n",
    "\n",
    "# Test : top ten words that follow 'me'\n",
    "# print(bigram_table['me'].most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10201d47",
   "metadata": {},
   "source": [
    "#### Part 2 - 3: Generate Predictions \"I am ... and Your are ...\"\n",
    "\n",
    "By using the Bigram model, simple predictions are made following `I am` and `You are`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c714bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_words(sentence, n_predictions):\n",
    "    predicted_words = bigram_table[sentence.split()[-1]].most_common()\n",
    "\n",
    "    # Form sentences (I removed some puncuation for cleaner words)\n",
    "    filered_words = []\n",
    "    for predictions in predicted_words:\n",
    "        if predictions[0].isalpha():\n",
    "            filered_words.append(predictions[0])\n",
    "        \n",
    "        if len(filered_words) == n_predictions:\n",
    "            break\n",
    "\n",
    "    return filered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "501399a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: I am not\n",
      "2: I am i\n",
      "3: I am a\n",
      "4: I am sure\n",
      "5: I am an\n",
      "6: I am innocent\n",
      "7: I am told\n",
      "8: I am very\n",
      "9: I am getting\n",
      "10: I am proud\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I am\"\n",
    "i_am_x = predict_next_words(sentence, 10)\n",
    "\n",
    "for count, result in enumerate(i_am_x):\n",
    "    print(str(count + 1) + \": \" + sentence + \" \" + result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76c282e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: You are not\n",
      "2: You are the\n",
      "3: You are in\n",
      "4: You are you\n",
      "5: You are a\n",
      "6: You are to\n",
      "7: You are used\n",
      "8: You are also\n",
      "9: You are now\n",
      "10: You are of\n"
     ]
    }
   ],
   "source": [
    "sentence = \"You are\"\n",
    "i_am_x = predict_next_words(sentence, 10)\n",
    "\n",
    "for count, result in enumerate(i_am_x):\n",
    "    print(str(count + 1) + \": \" + sentence + \" \" + result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda6f3a",
   "metadata": {},
   "source": [
    "#### Part 4: Calculate the probabilities of the predicted words\n",
    "\n",
    "To compute the probabilities of a sentence, use the **Bigram Formula** \n",
    "\n",
    "$$\\prod_{i=1}^{n} P(word_i|word_{i-1}) = \\prod_{i=1}^{n} \\frac{count(word_{i-1}, word_i)}{count(word_{i-1})}$$\n",
    "\n",
    "Note: Laplace smoothing (Add 1) was added, incase any raw counts have `zero`\n",
    "\n",
    "*modified bigram formula with laplace smoothing:*\n",
    "$$P_{LAP}(w_i | w_{i-1}) = \\frac {Count(w_{i-1},w_i) +1}{Count(w_{i-1, *}) + |V|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d777e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(set(tokens))\n",
    "def bigram_probabilities(previous_word, current_word):\n",
    "    count_numerator = bigram_table[previous_word][current_word]\n",
    "    count_denomenator = bigram_table[previous_word].N()\n",
    "\n",
    "    return (count_numerator + 1) / (count_denomenator + V)\n",
    "\n",
    "def compute_sentence_probability(sentence):\n",
    "    probability = 1.0\n",
    "\n",
    "    words = sentence.split()\n",
    "    words.insert(0, \"<s>\")\n",
    "    words.append(\"</s>\")\n",
    "\n",
    "    for i in range(1, len(words)):\n",
    "        probability *= bigram_probabilities(words[i-1].lower(),words[i].lower())\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0b6f12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not: 5.39e-13\n",
      "You are the: 2.15e-12\n",
      "You are in: 3.06e-13\n",
      "You are you: 3.77e-13\n",
      "You are a: 9.47e-13\n",
      "You are to: 2.06e-13\n",
      "You are used: 1.44e-13\n",
      "You are also: 1.43e-13\n",
      "You are now: 2.73e-13\n",
      "You are of: 7.58e-14\n"
     ]
    }
   ],
   "source": [
    "prefix = \"You are\"\n",
    "words = predict_next_words(prefix, 10)\n",
    "\n",
    "for word in words:\n",
    "    full_sentence = prefix + \" \" + word\n",
    "    p = compute_sentence_probability(full_sentence)\n",
    "    print(f\"{full_sentence}: {p:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69719cd7",
   "metadata": {},
   "source": [
    "#### Part 5: Computer Perplexity of the model\n",
    "\n",
    "`Perplexity` will measure how suprised the model is by a given sentence. A `high` perplexity the model is very suprised, a `low` perplexity the model is confident in it's predictions\n",
    "\n",
    "$$PP(sentence) = PP(sentence)^{-1/n}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4b4eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(sentence):\n",
    "    p = compute_sentence_probability(sentence)\n",
    "\n",
    "    words = sentence.split()\n",
    "    words.insert(0,\"<s>\")\n",
    "    words.append(\"</s>\")\n",
    "\n",
    "    return p ** (-1.0/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3faa80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_you_are = \"You are\"\n",
    "prefix_i_am = \"I am\"\n",
    "\n",
    "predictions_your_are = predict_next_words(prefix_you_are, 10)\n",
    "predictions_i_am = predict_next_words(prefix_i_am, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "203803eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not : perplexity = 284.23\n",
      "You are the : perplexity = 215.61\n",
      "You are in : perplexity = 318.27\n",
      "You are you : perplexity = 305.23\n",
      "You are a : perplexity = 253.94\n",
      "You are to : perplexity = 344.37\n",
      "You are used : perplexity = 370.10\n",
      "You are also : perplexity = 370.77\n",
      "You are now : perplexity = 325.73\n",
      "You are of : perplexity = 420.79\n"
     ]
    }
   ],
   "source": [
    "# you are \n",
    "for word in predictions_your_are:\n",
    "    sentence = prefix_you_are + \" \" + word\n",
    "    perplexity = compute_perplexity(sentence)\n",
    "    print(sentence, \": perplexity =\", f\"{perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256b392",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
