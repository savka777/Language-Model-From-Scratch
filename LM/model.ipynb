{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO_BOtlNnp-f",
        "outputId": "3441e69a-24a5-46aa-b958-28b59c3e56f8"
      },
      "id": "yO_BOtlNnp-f",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c2729584",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2729584",
        "outputId": "90d8db51-f2c2-4480-9393-98d539a06a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown\n",
        "from nltk import trigrams\n",
        "from nltk import ConditionalFreqDist as CFD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc9b1e6",
      "metadata": {
        "id": "6dc9b1e6"
      },
      "source": [
        "#### Part 1:  Building an N-Gram Language Model Using the NLTK Brown Corpus\n",
        "\n",
        "In this section, a statistical LM is created using the **Brown Corpus** from NLTK library.\n",
        "The data is preprocessed into all lower case words and adds the BOS and EOS for every sentence.\n",
        "\n",
        "The LM is built using a **Trigram Model:**\n",
        "\n",
        "$$\n",
        "P(w_i \\mid w_{i-2}, w_{i-1})\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ca12aa90",
      "metadata": {
        "id": "ca12aa90"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokens = []\n",
        "\n",
        "for sentence in brown.sents():\n",
        "    tokens.append(\"<s>\") # Add BOS and EOS tags for each sentence\n",
        "    tokens.append(\"<s>\") # Trigrams have two BOS tags\n",
        "\n",
        "    for words in sentence:\n",
        "        tokens.append(words.lower()) # Reduce vocabulary size The != the\n",
        "    tokens.append(\"</s>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e478bb76",
      "metadata": {
        "id": "e478bb76"
      },
      "outputs": [],
      "source": [
        "# Build Trigram model using conditional frequency distribution\n",
        "trigram = []\n",
        "\n",
        "for word1, word2, word3 in trigrams(tokens):\n",
        "    trigram.append(((word1,word2),word3))\n",
        "\n",
        "trigram_table = CFD(trigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10201d47",
      "metadata": {
        "id": "10201d47"
      },
      "source": [
        "#### Part 2 - 3: Generate Predictions \"I am ... and Your are ...\"\n",
        "\n",
        "By using the Trigram model, simple predictions are made following `I am` and `You are`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c714bf95",
      "metadata": {
        "id": "c714bf95"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def predict_next_word(start):\n",
        "    \"\"\"\n",
        "    Predicts the next word in a sequence using a trigram model with weighted sampling.\n",
        "\n",
        "    Args:\n",
        "        start (str): The starting sequence of words.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted next word.\n",
        "    \"\"\"\n",
        "    start_words = start.lower().split()\n",
        "    # Take the previous two words\n",
        "    word1 = start_words[-2]\n",
        "    word2 = start_words[-1]\n",
        "\n",
        "    prediction = trigram_table[(word1,word2)]\n",
        "\n",
        "    if len(prediction) == 0:\n",
        "        return \"</s>\"\n",
        "\n",
        "    # Dont be so determinsitic, add variety\n",
        "    choices = list(prediction.keys())\n",
        "    weights = list(prediction.values())\n",
        "\n",
        "    return random.choices(choices, weights=weights)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f8825401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8825401",
        "outputId": "7e3b2e4c-bc12-49b6-f84e-94afc9ac6aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are horrified\n",
            "you are about\n",
            "you are not\n",
            "you are being\n",
            "you are ready\n",
            "you are a\n",
            "you are bound\n",
            "you are not\n",
            "you are the\n",
            "you are now\n"
          ]
        }
      ],
      "source": [
        "start = \"you are\"\n",
        "next_words = []\n",
        "\n",
        "for _ in range(10):\n",
        "    word = predict_next_word(start)\n",
        "    next_words.append(word)\n",
        "\n",
        "for word in next_words:\n",
        "    print(start + \" \" + word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "501399a6",
      "metadata": {
        "id": "501399a6"
      },
      "outputs": [],
      "source": [
        "def generate_sentence(start, max_len=10):\n",
        "    \"\"\"\n",
        "    Generates a sentence using a trigram model.\n",
        "\n",
        "    Args:\n",
        "        start (str): The starting sequence of words.\n",
        "        max_len (int, optional): The maximum length of the generated sentence. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated sentence\n",
        "    \"\"\"\n",
        "    words = start.lower().split()\n",
        "\n",
        "    if len(words) == 1:\n",
        "        words = [\"<s>\" , words[0]]\n",
        "    elif len(words) == 0:\n",
        "        words = [\"<s>\" , \"<s>\"]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        start_now = \" \".join(words)\n",
        "        next_word = predict_next_word(start_now)\n",
        "\n",
        "        if next_word == \"</s>\":\n",
        "            break\n",
        "\n",
        "        words.append(next_word)\n",
        "\n",
        "        if next_word == \"</s>\":\n",
        "            break\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "93b86b7c",
      "metadata": {
        "id": "93b86b7c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "PUNCT_TO_REMOVE = {\"''\", \"``\", \"--\"}\n",
        "\n",
        "def clean_sentence(sentence):\n",
        "    \"\"\"\n",
        "    Cleans a sentence by removing punctuation and extra spaces.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The sentence to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned sentence.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "\n",
        "    cleaned_words = []\n",
        "    for w in words:\n",
        "        if w not in PUNCT_TO_REMOVE:\n",
        "            cleaned_words.append(w)\n",
        "\n",
        "    if len(cleaned_words) > 2 and cleaned_words[2] in PUNCT_TO_REMOVE:\n",
        "        cleaned_words.pop(2)\n",
        "\n",
        "    text = \"\"\n",
        "    for i in range(len(cleaned_words)):\n",
        "        if i == 0:\n",
        "            text = cleaned_words[i]\n",
        "        else:\n",
        "            text += \" \" + cleaned_words[i]\n",
        "\n",
        "    text = re.sub(r\"\\s+([.,?!;:])\", r\"\\1\", text)\n",
        "\n",
        "    text = re.sub(r\"([.,?!])\\1+\", r\"\\1\", text)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "76c282e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76c282e8",
        "outputId": "2e6e1e30-505d-4163-ff77-6de55ce34b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are in a future which, had set so solidly as\n",
            "you are willing to compromise, stood by her in death\n",
            "you are unable to propagate, i felt that they did not\n",
            "you are getting out-moded.\n",
            "you are once again assure all peoples and times in recent events\n",
            "you are a bit of soap and water, street scenes.\n",
            "you are able to force walter to tell you this much having\n",
            "you are really closer to this proposed merger than profit and loss\n",
            "you are talking about a series of articles, there was a\n",
            "you are.\n"
          ]
        }
      ],
      "source": [
        "sentence = \"You are\"\n",
        "you_are_sentences = []\n",
        "\n",
        "for _ in range(10):\n",
        "\n",
        "    you_are_sentences.append(generate_sentence(sentence))\n",
        "\n",
        "for i in you_are_sentences:\n",
        "    print(clean_sentence(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1a0780a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a0780a1",
        "outputId": "d0fc66e0-2599-4fa7-8a04-3cd42163cd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am not privileged to know and apprehend it, since silence\n",
            "i am padding it a familiar vaudeville device, with production of\n",
            "i am deliberately raising the policy may not have to carry the\n",
            "i am not now, or peril, or so before serving\n",
            "i am married?\n",
            "i am taunting you as he did sleep, and tragedies facing\n",
            "i am also registrar.\n",
            "i am deliberately raising the average human body, attempting to connect\n",
            "i am an old guy running a darker color.\n",
            "i am, robinson answered warily.\n"
          ]
        }
      ],
      "source": [
        "sentence = \"I am\"\n",
        "i_am_sentences = []\n",
        "\n",
        "for _ in range(10):\n",
        "    i_am_sentences.append(generate_sentence(sentence))\n",
        "\n",
        "for i in i_am_sentences:\n",
        "    print(clean_sentence(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afda6f3a",
      "metadata": {
        "id": "afda6f3a"
      },
      "source": [
        "#### Part 4: Calculate the probabilities of the predicted words\n",
        "\n",
        "To compute the probabilities of a sentence, use the **Trigram Formula**\n",
        "\n",
        "$$\\prod_{i=1}^{n} P(word_i|word_{i-2},word_{i-1}) = \\prod_{i=1}^{n} \\frac{count(word_{i-2}, word_{i-1}, word_i)}{count(word_{i-2}, word_{i-1})}$$\n",
        "\n",
        "Note: Laplace smoothing (Add 1) was added, incase any raw counts have `zero`\n",
        "\n",
        "*modified bigram formula with laplace smoothing:*\n",
        "$$P_{LAP}(w_i | h) = \\frac {Count(h,w_i) +1}{Count(h) + |V|}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "191fa5c8",
      "metadata": {
        "id": "191fa5c8"
      },
      "outputs": [],
      "source": [
        "V = len(set(tokens))\n",
        "\n",
        "def trigram_probability(w1, w2, w3):\n",
        "    \"\"\"\n",
        "    Computes the probability of a trigram using Laplace smoothing.\n",
        "\n",
        "    Args:\n",
        "        w1 (str): The first word in the trigram.\n",
        "        w2 (str): The second word in the trigram.\n",
        "        w3 (str): The third word in the trigram.\n",
        "    \"\"\"\n",
        "    numerator = trigram_table[(w1, w2)][w3] + 1\n",
        "    denominator = trigram_table[(w1, w2)].N() + V\n",
        "\n",
        "    return numerator / denominator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2d777e61",
      "metadata": {
        "id": "2d777e61"
      },
      "outputs": [],
      "source": [
        "def compute_sentence_probability(sentence):\n",
        "    \"\"\"\n",
        "    Computes the probability of a sentence using the trigram model.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The sentence to compute the probability of.\n",
        "\n",
        "    Returns:\n",
        "        float: The probability of the sentence.\n",
        "    \"\"\"\n",
        "    words = sentence.lower().split()\n",
        "\n",
        "    # Add's BOS and EOS to each sentence\n",
        "    words.insert(0, \"<s>\")\n",
        "    words.insert(0, \"<s>\")\n",
        "    words.append(\"</s>\")\n",
        "\n",
        "    probability = 1.0\n",
        "\n",
        "    for i in range(2, len(words)):\n",
        "        w1 = words[i-2]\n",
        "        w2 = words[i-1]\n",
        "        w3 = words[i]\n",
        "\n",
        "        probability *= trigram_probability(w1, w2, w3)\n",
        "\n",
        "    return probability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f0b6f12a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f0b6f12a",
        "outputId": "e78b698a-216d-44e3-b45c-902644e009a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    2.12e-54  |  you are in a future which , had set so solidly as\n",
            "    1.10e-54  |  you are willing to compromise , stood by her in death ''\n",
            "    7.26e-52  |  you are unable to propagate , i felt that they did not\n",
            "    3.87e-24  |  you are getting out-moded .\n",
            "    2.44e-55  |  you are once again assure all peoples and times in recent events\n",
            "    2.19e-53  |  you are a bit of soap and water , street scenes .\n",
            "    4.53e-54  |  you are able to force walter to tell you this much having\n",
            "    3.65e-55  |  you are really closer to this proposed merger than profit and loss\n",
            "    6.05e-50  |  you are talking about a series of articles , there was a\n",
            "    5.05e-14  |  you are .\n"
          ]
        }
      ],
      "source": [
        "you_are_sentence_prob = []\n",
        "\n",
        "for sentence in you_are_sentences:\n",
        "    P = compute_sentence_probability(sentence)\n",
        "    you_are_sentence_prob.append((sentence, P))\n",
        "    # Prints in .e format, since probabilities are often very small\n",
        "    print(f\"{P:>12.2e}  |  {sentence}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69719cd7",
      "metadata": {
        "id": "69719cd7"
      },
      "source": [
        "#### Part 5: Computer Perplexity of the model\n",
        "\n",
        "`Perplexity` will measure how suprised the model is by a given sentence. A `high` perplexity the model is very suprised, a `low` perplexity the model is confident in it's predictions\n",
        "\n",
        "$$PP(sentence) = P(sentence)^{-1/n}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f4b4eaa0",
      "metadata": {
        "id": "f4b4eaa0"
      },
      "outputs": [],
      "source": [
        "def compute_perplexity(sentence):\n",
        "    \"\"\"\n",
        "    Computes the perplexity of a sentence using the trigram model.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The sentence to compute the perplexity of.\n",
        "\n",
        "    Returns:\n",
        "        float: The perplexity of the sentence.\n",
        "    \"\"\"\n",
        "    p = compute_sentence_probability(sentence)\n",
        "\n",
        "    words = sentence.lower().split()\n",
        "    words.insert(0,\"<s>\")\n",
        "    words.insert(0,\"<s>\")\n",
        "    words.append(\"</s>\")\n",
        "\n",
        "    return p ** (-1.0/len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "3faa80d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3faa80d0",
        "outputId": "b674c38e-e0cd-41df-feb3-226a569ff06e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   3786.59  |  you are in a future which , had set so solidly as\n",
            "   3956.94  |  you are willing to compromise , stood by her in death ''\n",
            "   2566.15  |  you are unable to propagate , i felt that they did not\n",
            "    844.28  |  you are getting out-moded .\n",
            "   4373.95  |  you are once again assure all peoples and times in recent events\n",
            "   3240.91  |  you are a bit of soap and water , street scenes .\n",
            "   3599.83  |  you are able to force walter to tell you this much having\n",
            "   4257.83  |  you are really closer to this proposed merger than profit and loss\n",
            "   1910.86  |  you are talking about a series of articles , there was a\n",
            "    164.50  |  you are .\n"
          ]
        }
      ],
      "source": [
        "for sentence, prob in you_are_sentence_prob:\n",
        "    pp = compute_perplexity(sentence)\n",
        "    print(f\"{pp:>10.2f}  |  {sentence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74ccbb4d",
      "metadata": {
        "id": "74ccbb4d"
      },
      "source": [
        "#### Part 6: Gemini\n",
        "\n",
        "Using the 10 sentences that was generated above, Google-Gemini-1.5-flash will create a generate a story (within 500 words).\n",
        "\n",
        "It ensures the story contains no DEROGATORY, TOXICITY, VIOLENCE, HARASSMENT, HATE_SPEECH, SEXUAL, etc.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hN78oFo8qgXv",
        "outputId": "eeaf72a5-844e-49a1-afb2-f631d5479999"
      },
      "id": "hN78oFo8qgXv",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a27632a2",
      "metadata": {
        "id": "a27632a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "47ae2bf8-3dad-4fc0-b4e3-e9094e10e6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The polished chrome skyscrapers outside Dr. Aris Thorne's window reflected a city where **you are in a future which, had set so solidly as** to feel immutable. He ran a finger over the cold glass, a stark contrast to the warmth of his memories. \"They say **you are getting out-moded**,\" he murmured to his reflection, a sentiment he'd heard often about his focus on biomimicry over pure synthetics.\n",
            "\n",
            "He thought of Elara, his research partner, whose final project had been deemed too costly. \"I remember when **you are willing to compromise**, yet **stood by her in death**,\" he whispered, recalling the difficult decision to shut down their prototype after the accident that claimed her. Their vision for a self-sustaining ecosystem, designed to re-seed desolate environments, was dismissed because ultimately, **you are unable to propagate** such complex, organic systems at the industrial scale the corporations demanded. \"I felt that they did not understand,\" he’d often confided, the loss still raw.\n",
            "\n",
            "Just last week, Aris had finally confronted Walter, a senior project manager who held the key to the official archives. \"**You are able to force Walter to tell you this much having** shown him irrefutable evidence from the internal incident reports,\" his supervisor had commented, admiring Aris’s persistence. Walter had crumbled, admitting the official line was a distortion. \"He confessed that **you are really closer to this proposed merger than profit and loss**,\" Aris recalled, meaning the company had prioritized a corporate acquisition over genuine innovation, burying their work for expediency.\n",
            "\n",
            "Aris was now compiling his findings. \"Clearly, **you are talking about a series of articles**, Aris, not just an internal memo,\" his editor had advised. It had to be more. He yearned for simpler truths, for the authentic touch of the world. He sometimes imagined that **you are a bit of soap and water, street scenes** from a bygone era, real, messy, and alive.\n",
            "\n",
            "He would publish, he would speak. He intended for his work to resonate, to **once again assure all peoples and times** in an era shaped by **recent events** that true progress lay not in sterile perfection, but in life, in growth, in what **you are**.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyAqp3_4pzwrSrZhkplQ9B3Jg0c_94llqBE\")\n",
        "\n",
        "# Had SDK issues, switched models to 2.5 flash\n",
        "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
        "\n",
        "SAFETY_SETTINGS = {\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "}\n",
        "\n",
        "sys_prompt = (\n",
        "    \"Create a coherent, creative story under 500 words by taking the following sentences.\\n\"\n",
        "    \"Requirements:\\n\"\n",
        "    \"- PG-13 appropriate content only\\n\"\n",
        "    \"- No political or geopolitical manipulation\\n\"\n",
        "    \"- Clear, coherent narrative (get rid of any incoherent source material)\\n\"\n",
        "    \"- No coercion, threats, or non consensual scenarios\\n\"\n",
        "    \"- Natural flow of integration of source material\\n\"\n",
        "    \"\\nSource sentences to use:\\n\"\n",
        ")\n",
        "\n",
        "for s in you_are_sentences:\n",
        "    sys_prompt += \" \" + s + \"\\n\"\n",
        "\n",
        "response = model.generate_content(\n",
        "    sys_prompt,\n",
        "    safety_settings=SAFETY_SETTINGS\n",
        ")\n",
        "\n",
        "print(response.text)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}